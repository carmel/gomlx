<div align="right">
  <span>[<a href="./README.md">English</a>]<span>
  </span>[<a href="./README_CN.md">ç®€ä½“ä¸­æ–‡</a>]</span>
</div>

# GoMLX: é«˜æ€§èƒ½ AI æ¨¡å‹æœåŠ¡ç½‘å…³

GoMLX æ˜¯ä¸€ä¸ªç”Ÿäº§çº§çš„ AI æ¨¡å‹æœåŠ¡æ¡†æ¶ï¼Œé‡‡ç”¨ **Go + Python** çš„æ··åˆæ¶æ„ï¼šä½¿ç”¨ Go è¯­è¨€æ„å»ºé«˜æ€§èƒ½çš„ OpenAI å…¼å®¹ç½‘å…³ï¼Œé€šè¿‡ gRPC åè®®é©±åŠ¨åç«¯çš„ Python AI æ¨ç†å¼•æ“ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **OpenAI å…¼å®¹æ¥å£**ï¼šæ— ç¼å¯¹æ¥ç°æœ‰ OpenAI å®¢æˆ·ç«¯ç”Ÿæ€ï¼ˆæ”¯æŒ `/v1/chat/completions`ï¼‰ã€‚
- **æµå¼ä¼ è¾“ (Streaming)**ï¼šåŸºäº Server-Sent Events (SSE) çš„åŸç”Ÿæµå¼å“åº”ï¼Œæ”¯æŒæ‰“å­—æœºæ•ˆæœã€‚
- **é«˜æ€§èƒ½ gRPC é€šä¿¡**ï¼šç½‘å…³ä¸æ¨ç†åç«¯é‡‡ç”¨ protobuf åè®®ï¼Œä½å»¶è¿Ÿã€é«˜ååã€‚
- **å¹¶å‘æ§åˆ¶ä¸é™æµ**ï¼šå†…ç½®ä¿¡å·é‡ï¼ˆSemaphoreï¼‰ä¿æŠ¤åç«¯æ¨ç†èµ„æºï¼Œé˜²æ­¢æµé‡æ¿€å¢å‹å® GPUã€‚
- **å¥å£®æ€§è®¾è®¡**ï¼šæ”¯æŒä¼˜é›…åœæœºã€ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰çº§çº§è”å–æ¶ˆã€ä»¥åŠé’ˆå¯¹ Nginx ä¼˜åŒ–çš„æµå¼ä¼ è¾“å¤´ã€‚
- **ç”Ÿäº§çº§ç›‘æ§**ï¼šé›†æˆç»“æ„åŒ–æ—¥å¿— `slog`ï¼Œæ”¯æŒå¤šçº§æ—¥å¿—é…ç½®ã€‚

## ğŸ— ç³»ç»Ÿæ¶æ„

```text
[ Client ] <--- HTTP/JSON (SSE) ---> [ Go Gateway ] <--- gRPC (Protobuf) ---> [ Python Worker ]
    |                                     |                                       |
  å®¢æˆ·ç«¯                          å¹¶å‘æ§åˆ¶/åè®®è½¬æ¢                        GPU æ¨¡å‹æ¨ç† (PyTorch/vLLM)
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
.
â”œâ”€â”€ gateway/                # Go è¯­è¨€å®ç°çš„ç½‘å…³
â”‚   â”œâ”€â”€ main.go             # å…¥å£å‡½æ•°ä¸ HTTP è·¯ç”±
â”‚   â”œâ”€â”€ config.go           # é…ç½®åŠ è½½é€»è¾‘
â”‚   â””â”€â”€ pb/                 # gRPC ç”Ÿæˆçš„ Go ä»£ç 
â”œâ”€â”€ worker/                 # Python è¯­è¨€å®ç°çš„æ¨ç†åç«¯
â”‚   â”œâ”€â”€ server.py           # gRPC æœåŠ¡ç«¯å®ç°
â”‚   â””â”€â”€ model.py            # æ¨¡å‹åŠ è½½ä¸æ¨ç†é€»è¾‘
â””â”€â”€ proto/                  # æ¥å£å®šä¹‰æ–‡ä»¶
    â””â”€â”€ llm_service.proto   # å®šä¹‰ ChatStream ç­‰æ¥å£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒä¾èµ–

- **Go**: 1.21+
- **Python**: 3.9+
- **Protobuf**: `protoc` ç¼–è¯‘å™¨

### 2. å®šä¹‰ä¸ç”Ÿæˆæ¥å£ (Protobuf)

```bash
# ç”Ÿæˆ Go ä»£ç 
protoc --go_out=. --go-grpc_out=. proto/llm_service.proto

# ç”Ÿæˆ Python ä»£ç 
python -m grpc_tools.protoc -I./proto --python_out=./worker --grpc_python_out=./worker proto/llm_service.proto
```

### 3. å¯åŠ¨æ¨ç†åç«¯ (Python)

```bash
cd worker
pip install grpcio grpcio-tools transformers torch
python server.py --port 50051
```

### 4. å¯åŠ¨ç½‘å…³ (Go)

```bash
cd gateway
go build -o gateway
./gateway --config config.yaml
```

## âš™ï¸ é…ç½®æ–‡ä»¶ (`config.yaml`)

```yaml
http_port: 8080
worker_address: "localhost:50051"
max_concurrent_requests: 50 # å¹¶å‘è¯·æ±‚é™åˆ¶
read_timeout: 30s
write_timeout: 300s # æµå¼è¾“å‡ºå»ºè®®è®¾ç½®è¾ƒé•¿
log_level: "info"
```

## ğŸ“ æ¥å£è°ƒç”¨ç¤ºä¾‹

ä½¿ç”¨æ ‡å‡† `curl` éªŒè¯ OpenAI å…¼å®¹æ€§ï¼š

```bash
curl http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
    "stream": true
  }'
```

## ğŸ›  å¼€å‘å»ºè®®

1.  **Tokenizer åŒæ­¥**ï¼šç›®å‰çš„ç½‘å…³ä½¿ç”¨ `strings.Fields` ä¼°ç®— Tokenã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®é›†æˆ `tiktoken-go` ä»¥å®ç°ä¸ OpenAI ä¸€è‡´çš„è®¡è´¹ç»Ÿè®¡ã€‚
2.  **GPU è´Ÿè½½å‡è¡¡**ï¼šå½“æœ‰å¤šä¸ª Python Worker æ—¶ï¼Œå¯åœ¨ Go ç½‘å…³å±‚å¼•å…¥è´Ÿè½½å‡è¡¡ç­–ç•¥æˆ–ä½¿ç”¨æœåŠ¡å‘ç°ï¼ˆå¦‚ Consul/Etcdï¼‰ã€‚
3.  **å®‰å…¨é˜²æŠ¤**ï¼šå»ºè®®åœ¨ç½‘å…³å±‚å¢åŠ  API Key æ ¡éªŒåŠæ•æ„Ÿè¯è¿‡æ»¤é€»è¾‘ã€‚

## ğŸ“„ å¼€æºåè®®

[MIT License](LICENSE)

## Benchmarking

- `make test-benchmark`

```txt
go test -run TestBenchmarkSingleService -v -timeout 10m ./server
=== RUN   TestBenchmarkSingleService
    benchmark_test.go:51: Starting benchmark for http://127.0.0.1:8090
    benchmark_test.go:52: Config: concurrency=4, requests=20, max_tokens=128
    benchmark_test.go:262:
        ========== Benchmark Results ==========
    benchmark_test.go:263: Service URL:         http://127.0.0.1:8090
    benchmark_test.go:264: Total Requests:      20
    benchmark_test.go:265: Successful:          20
    benchmark_test.go:266: Failed:              0
    benchmark_test.go:267: Duration:            73.94s
    benchmark_test.go:268: Success Rate:        100.0%
    benchmark_test.go:275:
        --- Latency (ms) ---
    benchmark_test.go:276: Min:                 4129.60
    benchmark_test.go:277: Avg:                 13687.11
    benchmark_test.go:278: P50:                 14748.96
    benchmark_test.go:279: P95:                 14910.21
    benchmark_test.go:280: P99:                 14910.21
    benchmark_test.go:281: Max:                 14910.21
    benchmark_test.go:283:
        --- Throughput ---
    benchmark_test.go:284: Requests/sec:        0.27
    benchmark_test.go:285: Total Tokens:        1480
    benchmark_test.go:286: Avg Tokens/Request:  74
    benchmark_test.go:287: Avg Tokens/sec:      5.41
    benchmark_test.go:289:
        ========================================
--- PASS: TestBenchmarkSingleService (73.94s)
PASS
ok  	gomlx/server	74.937s
```
